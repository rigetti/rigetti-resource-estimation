# Copyright 2022-2025 Rigetti & Co, LLC
#
# This Computer Software is developed under Agreement HR00112230006 between Rigetti & Co, LLC and
# the Defense Advanced Research Projects Agency (DARPA). Use, duplication, or disclosure is subject
# to the restrictions as stated in Agreement HR00112230006 between the Government and the Performer.
# This Computer Software is provided to the U.S. Government with Unlimited Rights; refer to LICENSE
# file for Data Rights Statements. Any opinions, findings, conclusions or recommendations expressed
# in this material are those of the author(s) and do not necessarily reflect the views of the DARPA.
#
# Use of this work other than as specifically authorized by the U.S. Government is licensed under
# the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance
# with the License. You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software distributed under the License
# is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
# or implied. See the License for the specific language governing permissions and limitations under
# the License.

"""
**Module** ``rigetti_resource_estimation.graph_utils``

A set of utility functions and classes to generate and manipulate graph states for the purpose of resource estimations.
"""

import math
import logging
from pathlib import Path
from typing import Optional, Tuple, Literal, List
from dataclasses import dataclass
from collections import namedtuple

import json
import networkx as nx

from graph_state_generation.optimizers import greedy_stabilizer_measurement_scheduler
from graph_state_generation.substrate_scheduler import TwoRowSubstrateScheduler

from rigetti_resource_estimation.cabaliser_wrapper import CabaliserCompiler, create_nxgraph_from_adjdict

logger = logging.getLogger(__name__)


WidgetData = namedtuple("WidgetData", ["widget", "t_counts", "z_rot_counts", "clifford_counts"])


def process_graph(cab_data):
    graph = create_nxgraph_from_adjdict(cab_data["adjacencies"])
    _, sched = perform_substrate_scheduling(graph)
    size_g = len(graph)
    return sched, size_g


@dataclass
class CompilerSchedGraphItems:
    """
    A class to keep track of the graph state attributes for graphs generated by FT-compilers.

    The FT-compiler can be, for example, the default Cabaliser typically followed by Substrate Scheduler processing. It
    is more efficient and safer to store and manipulate NetworkX graph attributes rather than the original graph itself.

    :param rz_count: number of non-Clifford Rz gates associated with the graph, and also, original logical circuit.
    :param t_count_init: the initial T-count associated with input logical circuit prior to Clifford+T decompositions.
    :param clifford_count_init: number of explicit Clifford gates in the initial logical circuit.
    :param big_n: total number of graph nodes.
    :param delta: maximum number of logical qubits (max memory), required at any moment, based on initial data.
    :param prep_sched: the preparation schedule (from substrate scheduler) required for the execution of stabalizer
        measurements to initialize the graph.
    :param consump_sched: the schedule, provided by the Pauli Tracker, to consume the graph and execute the fault
        tolerant algorithm.
    :param measurement_basis_list: A list of measurement bases from the Pauli tracker, where each member is a list
        containing the bases that belong to the corresponding step of schedules.
    :param input_nodes: A list of input nodes, where each member is a list containing the input nodes that belong to
        the corresponding step of schedules.
    :param output_nodes: A list of output nodes, where each member is a list containing the output nodes that belong to
        the corresponding step of schedules.
    :param widget_cond_20to4: When True, the selected distillation widgets to feed the graph state are of `20to4` type.
    :param big_s_prep: Total number of graph prep measurement steps over all widgets.
    :param big_s_consump: Total number of graph consump measurement steps over all widgets.
    :param t_length_unit: the T-length of gate-synth chain for each Clifford+T decomposition of small angles.
    :param t_counting_cond: A flag to identify if T-counting approach was requested as the est method.
    """

    rz_count: int
    t_count_init: int
    clifford_count_init: int
    big_n: Optional[int] = None
    delta: Optional[int] = None
    prep_sched: Optional[List[List[List]]] = None
    consump_sched: Optional[List[List[List]]] = None
    measurement_basis_list: Optional[List[List]] = None
    input_nodes: Optional[List[List]] = None
    output_nodes: Optional[List[List]] = None
    widget_cond_20to4: Optional[bool] = False
    compiler_tag_table: Optional[dict] = None
    big_s_prep: Optional[int] = None
    big_s_consump: Optional[int] = None
    t_length_unit: int = 1
    t_counting_cond: bool = False

    def __post_init__(self):
        """Post-process some of the initial attributes."""
        if self.t_counting_cond:
            # We consider the worst case scenario of fully connected graphs, useful for T-counting methods:
            # the max graph node degree is a proxy for delta and is set equal to T-count>>1.
            self.delta = self.t_count_init + self.rz_count * self.t_length_unit
            # number of graph nodes equals to the total T-count.
            self.big_n = self.t_count_init + self.rz_count * self.t_length_unit

    def t_count(self) -> int:
        """Calculate total no. of T-basis measurements required at the distillation stage.

        Cabaliser only consumes Rz and T gates. We crudely assume there are one node in the graph state for each
        arbitrary Rz rotation and T, which also implies an upper bound estimate for time costs.
        """
        return self.t_count_init + self.rz_count * self.t_length_unit


def calculate_t_length_unit(const: Tuple[float, float], epsilon: float) -> int:
    """Calculate the length of T-gates required for arbitrary angle decomposition for an algorithm given ``const``.

    Currently, this in only required at the measurement points of the distillation stage, where gate synthesize
    to Clifford+T is performed to align rotation axes.

    :param const: set the constants required for gate-synth arbitrary-angle unitary decompositions.
    :param epsilson: the epsilon for Clifford+T decompositions of non-Clifford rotations.

    :returns: the T-length of gate-synth chain for each Clifford+T decomposition of small angles.
    """
    return math.ceil(const[0] * math.log2(1 / epsilon) + const[1])


def perform_substrate_scheduling(graph) -> Tuple[nx.Graph, List[List[Tuple[int, Tuple[int, int]]]]]:
    """Perform substrate scheduling for the consumption of a graph state and generate a schedule of measurements.

    This function uses substrate scheduling, compiling, and DAG tools from the open-source references:
    [1] https://github.com/zapatacomputing/benchq
    [3] https://github.com/sfc-aqua/gosc-graph-state-generation

    :param graph: A NetworkX graph state, supposed to be pre-processed by a FT-compiler such as Cabaliser.

    :returns:
        `graph`: A version of input graph state with no disconnected nodes.
        `schedule`: the substrate schedule for the preparation/initialization of the graph.
    """
    connected_graph = graph.copy()
    connected_graph.remove_nodes_from(list(nx.isolates(connected_graph)))  # removing isolated nodes
    connected_graph = nx.convert_node_labels_to_integers(connected_graph)

    scheduler_only_compiler = TwoRowSubstrateScheduler(
        connected_graph,
        stabilizer_scheduler=greedy_stabilizer_measurement_scheduler,
    )
    scheduler_only_compiler.run()
    prep_schedule = scheduler_only_compiler.measurement_steps

    logger.debug(
        "Substrate scheduling completed. The stab measurements required to initialize the graph state are:"
        f"\n{prep_schedule}\n"
    )

    return connected_graph, prep_schedule


class GraphGenerator:
    """A class to host fault tolerant compilation methods and generate graph states based on user choices."""

    def __init__(
        self,
        transpiled_widgets: dict,
        graph_state_opt: Literal["no_compile", "save", "resume"],
    ):
        """Initialize some graph state parameters based on user inputs.

        :param transpiled_widgets: RRE standard dict containing transpiled widgets info.
        :param graph_state_opt: What to do with respect to the graph state compilation. Options are explained below.
            'no_compile': The graph compilation pipeline will NOT be executed (relevant for, e.g., for 't_counting'
            approaches).
            'save': RRE compiles the subcircuit and attempt to generate the graph states and Pauli Frames info through
            Cabaliser compiler. The program will save all outputs in JSON file in the subdirectory
            `output/<circuit_fname>/`. The outputs will be named `<circuit_fname>_all0init_cabalizeframes.json`.
            'resume': RRE will try to resume the calculations assuming an `<circuit_fname>_all0init_cabalizeframes.json`
            already exist in `output/<circuit_fname>/` subdirectory.
        """
        self.transpiled_widgets = transpiled_widgets
        self.graph_state_opt = graph_state_opt
        self.circuit_fname = transpiled_widgets["circuit_name"]

    def generate_graph(self) -> CompilerSchedGraphItems:
        """Generate the graph state, consumption schedule, and Pauli Frames info."""
        transpiled_circs = {
            key: WidgetData(
                widget=self.transpiled_widgets["widgets"][key][0],
                t_counts=self.transpiled_widgets["widget_t_counts"][key],
                z_rot_counts=self.transpiled_widgets["widget_z_rot_counts"][key],
                clifford_counts=self.transpiled_widgets["widget_clifford_counts"][key],
            )
            for key in self.transpiled_widgets["widgets"].keys()
        }

        transpiled_circs_list = list(transpiled_circs.values())
        n_widgets = len(transpiled_circs_list)
        widget_keys = list(self.transpiled_widgets["widgets"].keys())
        cabalise_data_list = []
        logger.info(f"RRE received the following list of transpiled widgets to compile:\n{transpiled_circs_list}\n")

        if self.graph_state_opt == "resume":
            for nn in range(n_widgets):
                widget_suffix = "_" + widget_keys[nn]
                cabalise_json_path = (
                    "output/"
                    + self.circuit_fname
                    + "/"
                    + self.circuit_fname
                    + widget_suffix
                    + "_all0init_cabalizeframes.json"
                )
                if Path(cabalise_json_path).is_file():
                    logger.info(f"RRE will resume calculations from existing {cabalise_json_path} file.")
                    with open(cabalise_json_path, encoding="utf8") as json_file:
                        cabalise_data_list.append(json.load(json_file)[0])
                else:
                    raise FileNotFoundError(f"Cabaliser's JSON file of {cabalise_json_path} does not exist.")

        elif self.graph_state_opt == "save":
            logger.info(
                "RRE will generate and save the graph state, scheduling, and frames info as JSONs in output/ ..."
            )
            cabaliser_compiler = CabaliserCompiler(
                circuit_fname=self.circuit_fname, graph_state_opt=self.graph_state_opt
            )
            for nn in range(n_widgets):
                widget_suffix = "_" + widget_keys[nn]
                logger.info(
                    f"RRE will next compile transpiled widget {widget_keys[nn]} through Cabaliser with the params:\n"
                    f"\ttranspiled_widget: {transpiled_circs_list[nn]}\n"
                    f"\tinput_qubits: {self.transpiled_widgets['input_qubits']}\n"
                )
                cabalise_data = cabaliser_compiler.compile(
                    transpiled_widget=transpiled_circs_list[nn].widget,
                    input_qubits=self.transpiled_widgets["input_qubits"],
                    max_memory_qubits=int(  # Tightest bound should be twice of no. of input qubits + non-Clifford ops.
                        2 * self.transpiled_widgets["input_qubits"]
                        + transpiled_circs_list[nn].t_counts
                        + transpiled_circs_list[nn].z_rot_counts
                        + 1  # +1 since counts may be zero; 2*(input_qubits) will throw error
                    ),
                    widget_suffix=widget_suffix,
                )
                logger.debug(
                    f"\nFor widget of position {nn}, RRE compiled the following `cabalise_data`:\n{cabalise_data}\n"
                )
                cabalise_data_list.append(cabalise_data)

        else:
            raise RuntimeError("Specify a valid 'graph_state_opt' for the 'cabaliser' compilation method.")

        graph_items = CompilerSchedGraphItems(
            t_count_init=self.transpiled_widgets["init_t_count"],
            rz_count=self.transpiled_widgets["init_rz_count"],
            clifford_count_init=self.transpiled_widgets["init_clifford_count"],
            compiler_tag_table=self.transpiled_widgets["compiler_tag_table"],
        )

        graph_items = self.stitch_graphs(cabalise_data_list)
        del cabalise_data_list

        return graph_items

    def stitch_graphs(self, cabalise_data_list: list[dict]) -> CompilerSchedGraphItems:
        """
        Stitch graph items to build a unified item comprised of repetition patterns of distinct widgets.

        For resource estimation purposes, one does not need to formally stitch universal graphs. It would be sufficient
        just to accumulate schedules and keep track of graph sizes as we do below. This module can be considered a
        dummy-style stitcher.
        """
        widget_keys = list(self.transpiled_widgets["widgets"].keys())

        logger.debug(
            "Stitching `graph_items` based on the following widgetization data:\n"
            f"\twidget_keys: {widget_keys}\n"
            f"\ttranspiled_widgets_stitches: {self.transpiled_widgets['stitches']}\n"
            f"\tcabalise_data_list: {cabalise_data_list}\n"
        )

        # process the schedules and the graphs for the compiled widgets
        prep_schedule, graph_sizes = zip(*[process_graph(cab_data) for cab_data in cabalise_data_list])
        mbl = [cabalise_data_list[idx]["measurement_tags"] for idx in range(len(cabalise_data_list))]
        consump_sched = [cabalise_data_list[idx]["consumptionschedule"] for idx in range(len(cabalise_data_list))]
        input_nodes = [cabalise_data_list[idx]["statenodes"] for idx in range(len(cabalise_data_list))]
        output_nodes = [cabalise_data_list[idx]["outputnodes"] for idx in range(len(cabalise_data_list))]
        delta = max([cabalise_data_list[idx]["space"] for idx in range(len(cabalise_data_list))])

        big_n = sum(
            [
                graph_sizes[widget_keys.index(label)] * reps
                for label, (_, reps) in self.transpiled_widgets["widgets"].items()
            ]
        )
        # For every widget-to-widget crossing, we must add n_output_nodes to N:
        big_n += sum([value for value in list(self.transpiled_widgets["stitches"].values())]) * len(output_nodes[0])

        big_s_prep = sum(
            [
                sum([len(subsched) for subsched in prep_schedule[widget_keys.index(label)]]) * reps
                for label, (_, reps) in self.transpiled_widgets["widgets"].items()
            ]
        )
        big_s_consump = sum(
            [
                sum([len(subsched) for subsched in consump_sched[widget_keys.index(label)]]) * reps
                for label, (_, reps) in self.transpiled_widgets["widgets"].items()
            ]
        )

        graph_items = CompilerSchedGraphItems(
            t_count_init=self.transpiled_widgets["init_t_count"],
            rz_count=self.transpiled_widgets["init_rz_count"],
            clifford_count_init=self.transpiled_widgets["init_clifford_count"],
            compiler_tag_table=self.transpiled_widgets["compiler_tag_table"],
            big_n=big_n,
            delta=delta,
            prep_sched=prep_schedule,  # type: ignore
            input_nodes=input_nodes,
            output_nodes=output_nodes,
            consump_sched=consump_sched,
            measurement_basis_list=mbl,
            big_s_prep=big_s_prep,
            big_s_consump=big_s_consump,
        )

        return graph_items


def find_graph_info(
    est_method: str,
    transpiled_widgets: dict,
    graph_state_opt: Literal["no_compile", "save", "resume"],
) -> CompilerSchedGraphItems:
    """Build the graph state and store its attributes based on given ``est_method`` and graph-state options.

    If graph creation not required (as in `t_counting` method), it outputs `None` for the required number of logical
    nodes and other relevant quantities.

    :param est_method: The estimation method to perform resource estimations. The method will measure if further
        processing and pinpointing of other parameters, such as gate-synth `eps` is required. You can set it to either:
        't_counting': Considers the total T-count as a proxy for the graph's size and max degree to estimate all
        resources required (similar to the underlying approaches by other libraries such as LatticeSurgery.com and
        Microsoft Quantum Azure).
        'cabaliser': Use Cabiliser compilation tools to generate the graph properties explicitly.
    :param transpiled_widgets: RRE standard dict containing transpiled widgets info.
    :param graph_state_opt: What to do concerning the graph state compilation. We explain the available options below.
        'no_compile': The graph compilation pipeline will NOT be executed (relevant for, e.g., 't_counting'
        approaches).
        'save': RRE compiles the subcircuit and attempt to generate the graph states and Pauli Frames info through
        Cabaliser compiler. The program will save all outputs in JSON file in the subdirectory
        `output/<circuit_fname>/`. The outputs will be named `<circuit_fname>_all0init_cabalizeframes.json`.
        'resume': RRE will try to resume the calculations assuming an `<circuit_fname>_all0init_cabalizeframes.json`
        already exist in `output/<circuit_fname>/` subdirectory.

    :returns: A CompilerSchedGraphItems object containing the graph state attributes.
    """
    if est_method == "cabaliser":
        logger.info("Initializing graph state processing for the `cabaliser` method.")
        graph_generator = GraphGenerator(
            graph_state_opt=graph_state_opt,
            transpiled_widgets=transpiled_widgets,
        )
        return graph_generator.generate_graph()

    elif est_method == "t_counting":
        if graph_state_opt != "no_compile":
            raise ValueError(
                f"The est_method={est_method} and graph_state_opt={graph_state_opt} cannot be selected together!"
            )
        graph_items = CompilerSchedGraphItems(
            t_count_init=transpiled_widgets["init_t_count"],
            rz_count=transpiled_widgets["init_rz_count"],
            clifford_count_init=transpiled_widgets["init_clifford_count"],
            t_counting_cond=True,
        )

    else:
        raise ValueError(f"The est_method={est_method} is not supported!")

    logger.debug(
        "The full `graph_items` object was constructed with the following attributes:\n"
        f"N: {graph_items.big_n}\n"
        f"rz_count: {graph_items.rz_count}\n"
        f"t_count_init: {graph_items.t_count_init}\n"
        f"delta: {graph_items.delta}\n"
        f"prep_sched: {graph_items.prep_sched}\n"
        f"consump_sched: {graph_items.consump_sched}\n"
        f"output_nodes: {graph_items.output_nodes}\n"
        f"measurement_basis_list: {graph_items.measurement_basis_list}\n"
    )

    return graph_items
